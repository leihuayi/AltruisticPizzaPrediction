{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c22843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25458ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "path_df = \"pickles/df.pickle\"\n",
    "with open(path_df, 'rb') as data:\n",
    "    df = pickle.load(data)\n",
    "\n",
    "# features_train\n",
    "path_features_train = \"pickles/features_train.pickle\"\n",
    "with open(path_features_train, 'rb') as data:\n",
    "    features_train = pickle.load(data)\n",
    "\n",
    "# labels_train\n",
    "path_labels_train = \"pickles/labels_train.pickle\"\n",
    "with open(path_labels_train, 'rb') as data:\n",
    "    labels_train = pickle.load(data)\n",
    "\n",
    "# features_test\n",
    "path_features_test = \"pickles/features_test.pickle\"\n",
    "with open(path_features_test, 'rb') as data:\n",
    "    features_test = pickle.load(data)\n",
    "\n",
    "# labels_test\n",
    "path_labels_test = \"pickles/labels_test.pickle\"\n",
    "with open(path_labels_test, 'rb') as data:\n",
    "    labels_test = pickle.load(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4935e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7a8a4",
   "metadata": {},
   "source": [
    "# Simple training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbc06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', class_weight={0: 0.25, 1:0.75})\n",
    "svc.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = svc.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d42d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The training accuracy is: \", accuracy_score(labels_train, svc.predict(features_train)))\n",
    "print(\"The test accuracy is: \", accuracy_score(labels_test, svc_pred))\n",
    "\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,svc_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbda3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(labels_test, svc_pred, normalize='true')\n",
    "plt.figure(figsize=(12.8,6))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True,\n",
    "            xticklabels=[0,1], \n",
    "            yticklabels=[0,1],\n",
    "            cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeeed12",
   "metadata": {},
   "source": [
    "# More complex training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab76c9",
   "metadata": {},
   "source": [
    "## Randomized search cross-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f535c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# C\n",
    "C = [.0001, .001, .01]\n",
    "\n",
    "# gamma\n",
    "gamma = [.0001, .001, .01, .1, 1, 10, 100]\n",
    "\n",
    "# degree\n",
    "degree = [1, 2, 3, 4, 5]\n",
    "\n",
    "# kernel\n",
    "kernel = ['linear', 'rbf', 'poly']\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'C': C,\n",
    "              'kernel': kernel,\n",
    "              'gamma': gamma,\n",
    "              'degree': degree,\n",
    "             }\n",
    "\n",
    "\n",
    "\n",
    "# First create the base model to tune\n",
    "svc = svm.SVC(class_weight='balanced')\n",
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=svc,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=3, \n",
    "                                   verbose=1)\n",
    "\n",
    "t = time.time()\n",
    "# Fit the random search model\n",
    "random_search.fit(features_train, labels_train)\n",
    "print('Finished search grid in', time.time()-t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed87bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "C = [.00001, .0001, .001]\n",
    "degree = [3, 4, 5]\n",
    "gamma = [0.1, 1, 10]\n",
    "probability = [True]\n",
    "\n",
    "param_grid = [\n",
    "  {'C': C, 'kernel':['linear'], 'degree':degree},\n",
    "  {'C': C, 'kernel':['linear'], 'gamma':gamma}\n",
    "]\n",
    "\n",
    "# Create a base model\n",
    "svc = svm.SVC(class_weight='balanced')\n",
    "\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=svc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(features_train, labels_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6667b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best hyperparameters from Grid Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d051ec3",
   "metadata": {},
   "source": [
    "### Apply best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce87d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', class_weight={0: 0.25, 1:0.75}, gamma=1, degree=4, C=0.0001)\n",
    "svc.fit(features_train, labels_train)\n",
    "svc_pred = svc.predict(features_test)\n",
    "print(\"The training accuracy is: \", accuracy_score(labels_train, svc.predict(features_train)))\n",
    "print(\"The test accuracy is: \", accuracy_score(labels_test, svc_pred))\n",
    "\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45705c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(labels_test, svc_pred, normalize='true')\n",
    "plt.figure(figsize=(12.8,6))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True,\n",
    "            xticklabels=[0,1], \n",
    "            yticklabels=[0,1],\n",
    "            cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41dbc34",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "## Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995887a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "punctuation = list(\",.?!(){}[]-_\\\"'\\\\;:+*<>@#ยง^$%&|/\") + ['\\n', '\\r', '\\t', '...', '..']\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add(\"request\")\n",
    "stop_words.add(\"edit\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tag_dict = {\"J\": wn.ADJ,\n",
    "            \"N\": wn.NOUN,\n",
    "            \"V\": wn.VERB,\n",
    "            \"R\": wn.ADV}\n",
    "\n",
    "def extract_wnpostag_from_postag(tag):\n",
    "    #take the first letter of the tag\n",
    "    #the second parameter is an \"optional\" in case of missing key in the dictionary \n",
    "    return tag_dict.get(tag[0].upper(), None)\n",
    "\n",
    "def lemmatize_tupla_word_postag(tupla):\n",
    "    \"\"\"\n",
    "    giving a tupla of the form (wordString, posTagString) like ('guitar', 'NN'), return the lemmatized word\n",
    "    \"\"\"\n",
    "    tag = extract_wnpostag_from_postag(tupla[1])    \n",
    "    return lemmatizer.lemmatize(tupla[0], tag) if tag is not None else tupla[0]\n",
    "\n",
    "def correspondance_miswrite(word):\n",
    "    if word == \"im\":\n",
    "        return \"i'm\"\n",
    "    elif word == \"ive\":\n",
    "        return \"i've\"\n",
    "\n",
    "def clean_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    original_words = word_tokenize(sentence)\n",
    "    tagged_words = nltk.pos_tag(original_words) #returns a list of tuples: (word, tagString) like ('And', 'CC')\n",
    "    lemmatized_words = [ lemmatize_tupla_word_postag(ow) for ow in tagged_words ]\n",
    "    cleaned_words = [ \n",
    "        w for w in lemmatized_words if (w not in punctuation) and (w not in stop_words)\n",
    "    ]\n",
    "    return ' '.join(cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "with open('pickles/vectorizer.pickle', 'rb') as data:\n",
    "    vectorizer = pickle.load(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765a4de",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Just started my new job and my paycheck hasn't rolled in yet.\\\n",
    "I am down to my last dollar now. Would love a pizza in these trying times. I have held strong for 3 months.\\n\\n\\\n",
    "I do also intent to pay-it-forward when I can afford it in a couple of months. Much appreciated!\\n\\n\\\n",
    "Edit: I failed to mention I am in Toronto! Nearby pizza chains include 241, Dominoes and Pizza Pizza.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7bd283",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputt = [clean_text(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afaed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_input = vectorizer.transform(inputt).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.predict(features_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a009527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
